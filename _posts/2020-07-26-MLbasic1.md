---
title: Machine Learning Basic_1
description: ML fundamentals 1
categories:
  - machine-learning
tags:
toc: true
toc_sticky: true
comments: true
excerpt: |
  ML Pipeline / Key Terminology /
# header:
#   image: /assets/images/logos/logo-text-8c3ba8a6.svg
---

# Introduction

Why machine learning? Many industry companies use machine learning to be specialized and differentiated by intelligent applications. For instance, early days, Amazon disrupted the retail market by introducing product recommendations to their website, Google disrupted the advertising market by targeting the new customers who have similar behaviors to the existing customers, and Uber disrupted the taxi industry by optimizing how to connect drivers with customers in real time. Such tech made their products special.

# Machine Learning Pipeline

ML pipeline is simply to train a model. Machine learning pipelines iteratively improves the current model that you created for a better output. Data proliferation tremendously affect your decision-making valued or misvalued, depending on your approach and data manipulation.

![ML Pipeline](/assets/images/ml_basic1/pl.png){:height="700px" width="400px"}  
| Fig1. ML Pipeline|

Every data is not labeled: mostly unlabeled. ML method (algorithm) is based on your goal and the data type. Under the 3 categories (Supervised Learning, Unsupervised Learning, and Reinforcement Learning), the 'method' including learning process varies. The following figure and table may clearly show what they are and when to use.

![ML Type](/assets/images/ml_basic1/MLtype.png){:height="700px" width="400px"}  
| Fig2. ML Type|

| Type           |    Supervised     |   Unsupervised      |    Reinforcement    |
|:--------------:|:-----------------:|:-------------------:|:-------------------:|
| **Input**      |  Data with Label  | Data without Label  | states and actions  |
|**Problem Type**| Regression,       | Clustering,         | Exploitation,       |
|                | Classification    | Association         | Exploration         |
|**Algorithm**   | Linear Regress.,  | K-Means, C-Means,   | Q-Learning, SARSA,  |
|                | Logistic Regress.,|Apriori, DBSCAN, GAN,|Monte Carlo, TD, etc.|    
|                | SVM, KNN, etc.    | Autoencoder, etc.   |                     |
| **Goal**       | Predict outcomes  | Discover underlying | Learn a series of   | |                |                   | patterns            | actions             |
|**Application** | Risk Evaluation,  | Recommender,        | Self Driving Cars,  |
|                | Forecast Sales, ..| Anomaly Detector, ..|Gaming, Healthcare,..|
{:.table-striped}
| Table1. ML Type|

For a better learning process and delivery, ML pipeline should have the following processes:
- Data collection
- Data cleaning (Data Wrangling)
- Feature extraction / Feature selection
- Model evaluation (Evaluation Metrics)
- Visualization

If you are interested in more details, Check [here](https://sebastianraschka.com/Articles/2014_intro_supervised_learning.html).


# Terminology

## Labels
A label is the real value that we're predicting - $$y$$ variable (dependent variable). For example, a label could be a real housing price, a real species animal in a picture, an actual meaning of an audio clip, etc.

## Features
A feature is an input variable - $$x$$ variable (independent variable). A simple ML problem could have a single feature; it depends on how we define a problem. Suppose that housing price replies on only size. Then, we have one independent variable (house size) that affects one dependent variable (housing price).

NOTE: if a problem is set up more complicated having $$N$$ features, then the features can be expressed as $$x_1, x_2, x_3, ..., x_N$$.

More real example can be a spam detector. Then, features are:
- $$x_1$$: words in the email text
- $$x_2$$: sender's email address
- $$x_3$$: time that the email was sent
- $$x_4$$: the particular phrases that a spam usually has

## Examples
An example is a particular instance of data, $$\overrightarrow{x}$$ (boldface indicate a vector). A labeled example has both feature(s) and the label.
``` labeled examples: {features, label}: (x, y) ```

The following table shows 5 labeled examples from a housing price data set.

![SL example](/assets/images/ml_basic1/SL_ex.png){:height="700px" width="400px"}  
| Table2. Labeled example|

| **_NOTE:_** unlabeled examples: {features, ?}: (x, ?)

There are 3 unlabeled examples from the same housing price data set, which do not have a label (medianHouseValue).

![USL example](/assets/images/ml_basic1/USL_ex.png){:height="700px" width="400px"}  
| Table2. Unlabeled example|

Once trained our model with labeled examples, we use that model to predict the label on unlabeled examples. Similarly, in the spam detector, unlabeled examples are new upcoming emails which don't have labels.

## Models
A model defines the relationship between features and label. You feed labeled examples to the model and enable the model to learn the relationships between features and label. That learning process is called 'training'.

Inference means applying the trained model to unlabeled examples. That is, you let the trained model predicts estimated value ($$\hat y$$) from training. During inference, in the spam filter example, your model can predict which are spam emails among newly upcoming emails. Similarly, in housing price estimator, your model can predict medianHouseValue for new unlabeled examples.

## Regression / Classification
A regression model predicts continuous values like housing price.
A classification model predicts discrete values like spam or not, dog or cat, etc.
